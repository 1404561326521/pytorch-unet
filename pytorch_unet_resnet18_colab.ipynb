{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-unet-resnet18-colab.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOTjcPzJXEpQRLkRUbsaQdG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usuyama/pytorch-unet/blob/master/pytorch_unet_resnet18_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lcY1ziTLblo",
        "colab_type": "text"
      },
      "source": [
        "## pytorch-uent\n",
        "\n",
        "https://github.com/usuyama/pytorch-unet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUvckFGU-4HE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "89b51a13-aa0f-4069-f2a0-ce54ccd2d972"
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"pytorch-unet\"):\n",
        "  !git clone https://github.com/usuyama/pytorch-unet.git\n",
        "\n",
        "%cd pytorch-unet"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-unet'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Total 55 (delta 0), reused 0 (delta 0), pack-reused 55\u001b[K\n",
            "Unpacking objects: 100% (55/55), done.\n",
            "/content/pytorch-unet/pytorch-unet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAx84Zg1_RnV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f54e04cd-ee6b-4790-f46c-cf0a1dc6f25b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "helper.py  loss.py\t\t\tpytorch_unet.ipynb  simulation.py\n",
            "images\t   pytorch_fcn.ipynb\t\tpytorch_unet.py\n",
            "LICENSE    pytorch_resnet18_unet.ipynb\tREADME.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N90-BlegJZfs",
        "colab_type": "text"
      },
      "source": [
        "## Enabling GPU on Colab\n",
        "\n",
        "Need to enable GPU from Notebook settings\n",
        "\n",
        "- Navigate to Edit-Notebook settings menu\n",
        "- Select GPU from the Hardware Accelerator dropdown list\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCitpQdkJNdI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c4511594-bdd3-451f-e0d0-4008512cd96c"
      },
      "source": [
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "  raise Exception(\"GPU not availalbe. CPU training will be too slow.\")\n",
        "\n",
        "print(\"device name\", torch.cuda.get_device_name(0))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device name Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8nZ6_mKMsJs",
        "colab_type": "text"
      },
      "source": [
        "## Synthetic images for demo training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qt0VHVZ_53z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "030d0dd7-5c58-40e0-af38-667325961b0f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import helper\n",
        "import simulation\n",
        "\n",
        "# Generate some random images\n",
        "input_images, target_masks = simulation.generate_random_data(192, 192, count=3)\n",
        "\n",
        "print(\"input_images shape and range\", input_images.shape, input_images.min(), input_images.max())\n",
        "print(\"target_masks shape and range\", target_masks.shape, target_masks.min(), target_masks.max())\n",
        "\n",
        "# Change channel-order and make 3 channels for matplot\n",
        "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
        "\n",
        "# Map each channel (i.e. class) to each color\n",
        "target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_images shape and range (3, 192, 192, 3) 0 255\n",
            "target_masks shape and range (3, 6, 192, 192) 0.0 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t16ni593BSUE",
        "colab_type": "text"
      },
      "source": [
        "# Left: Input image (black and white), Right: Target mask (6ch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzjh6C1HBTCb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "20aaa732-8b68-4c38-8484-f4363e13ce34"
      },
      "source": [
        "helper.plot_side_by_side([input_images_rgb, target_masks_rgb])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x864 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg2FqLRGBEJT",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-UTr03eAROb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "class SimDataset(Dataset):\n",
        "  def __init__(self, count, transform=None):\n",
        "    self.input_images, self.target_masks = simulation.generate_random_data(192, 192, count=count)\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image = self.input_images[idx]\n",
        "    mask = self.target_masks[idx]\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return [image, mask]\n",
        "\n",
        "# use the same transformations for train/val in this example\n",
        "trans = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
        "])\n",
        "\n",
        "train_set = SimDataset(2000, transform = trans)\n",
        "val_set = SimDataset(200, transform = trans)\n",
        "\n",
        "image_datasets = {\n",
        "  'train': train_set, 'val': val_set\n",
        "}\n",
        "\n",
        "batch_size = 25\n",
        "\n",
        "dataloaders = {\n",
        "  'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
        "  'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "}"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtkJTyxGB-XB",
        "colab_type": "text"
      },
      "source": [
        "## Check the outputs from DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRIOwoQvBKPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "b26222a4-4901-4d57-9474-f73cff5bb024"
      },
      "source": [
        "import torchvision.utils\n",
        "\n",
        "def reverse_transform(inp):\n",
        "  inp = inp.numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  inp = std * inp + mean\n",
        "  inp = np.clip(inp, 0, 1)\n",
        "  inp = (inp * 255).astype(np.uint8)\n",
        "\n",
        "  return inp\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, masks = next(iter(dataloaders['train']))\n",
        "\n",
        "print(inputs.shape, masks.shape)\n",
        "\n",
        "plt.imshow(reverse_transform(inputs[3]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25, 3, 192, 192]) torch.Size([25, 6, 192, 192])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7cf7eeb6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7XRZIKtCN8E",
        "colab_type": "text"
      },
      "source": [
        "# Define a UNet module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8EJl0hcC5DH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models\n",
        "\n",
        "\n",
        "def convrelu(in_channels, out_channels, kernel, padding):\n",
        "  return nn.Sequential(\n",
        "    nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
        "    nn.ReLU(inplace=True),\n",
        "  )\n",
        "\n",
        "\n",
        "class ResNetUNet(nn.Module):\n",
        "  def __init__(self, n_class):\n",
        "    super().__init__()\n",
        "\n",
        "    self.base_model = torchvision.models.resnet18(pretrained=True)\n",
        "    self.base_layers = list(self.base_model.children())\n",
        "\n",
        "    self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
        "    self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
        "    self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n",
        "    self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
        "    self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n",
        "    self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
        "    self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n",
        "    self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
        "    self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
        "    self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
        "\n",
        "    self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "    self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
        "    self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
        "    self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
        "    self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
        "\n",
        "    self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
        "    self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
        "    self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
        "\n",
        "    self.conv_last = nn.Conv2d(64, n_class, 1)\n",
        "\n",
        "  def forward(self, input):\n",
        "    x_original = self.conv_original_size0(input)\n",
        "    x_original = self.conv_original_size1(x_original)\n",
        "\n",
        "    layer0 = self.layer0(input)\n",
        "    layer1 = self.layer1(layer0)\n",
        "    layer2 = self.layer2(layer1)\n",
        "    layer3 = self.layer3(layer2)\n",
        "    layer4 = self.layer4(layer3)\n",
        "\n",
        "    layer4 = self.layer4_1x1(layer4)\n",
        "    x = self.upsample(layer4)\n",
        "    layer3 = self.layer3_1x1(layer3)\n",
        "    x = torch.cat([x, layer3], dim=1)\n",
        "    x = self.conv_up3(x)\n",
        "\n",
        "    x = self.upsample(x)\n",
        "    layer2 = self.layer2_1x1(layer2)\n",
        "    x = torch.cat([x, layer2], dim=1)\n",
        "    x = self.conv_up2(x)\n",
        "\n",
        "    x = self.upsample(x)\n",
        "    layer1 = self.layer1_1x1(layer1)\n",
        "    x = torch.cat([x, layer1], dim=1)\n",
        "    x = self.conv_up1(x)\n",
        "\n",
        "    x = self.upsample(x)\n",
        "    layer0 = self.layer0_1x1(layer0)\n",
        "    x = torch.cat([x, layer0], dim=1)\n",
        "    x = self.conv_up0(x)\n",
        "\n",
        "    x = self.upsample(x)\n",
        "    x = torch.cat([x, x_original], dim=1)\n",
        "    x = self.conv_original_size2(x)\n",
        "\n",
        "    out = self.conv_last(x)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ65Br1oDCOX",
        "colab_type": "text"
      },
      "source": [
        "## Instantiate the UNet model\n",
        "\n",
        "- Move the model to GPU if available\n",
        "- Show model summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY0Vk2VDCAiz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7cbb47f6-e011-4cda-c976-8b4268e0b6ae"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_unet\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device', device)\n",
        "\n",
        "model = ResNetUNet(6)\n",
        "model = model.to(device)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaZdFgOnGA_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c75d385c-f630-41ba-dd61-2fac19859de7"
      },
      "source": [
        "model"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNetUNet(\n",
              "  (base_model): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              "  )\n",
              "  (layer0): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (layer0_1x1): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (layer1): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer1_1x1): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2_1x1): Sequential(\n",
              "    (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3_1x1): Sequential(\n",
              "    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4_1x1): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "  (conv_up3): Sequential(\n",
              "    (0): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv_up2): Sequential(\n",
              "    (0): Conv2d(640, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv_up1): Sequential(\n",
              "    (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv_up0): Sequential(\n",
              "    (0): Conv2d(320, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv_original_size0): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv_original_size1): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv_original_size2): Sequential(\n",
              "    (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv_last): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoVYhHpbCSdY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07ae1340-879a-45a8-e172-de8f365b8dec"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model, input_size=(3, 224, 224))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-2         [-1, 64, 224, 224]               0\n",
            "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
            "              ReLU-4         [-1, 64, 224, 224]               0\n",
            "            Conv2d-5         [-1, 64, 112, 112]           9,408\n",
            "            Conv2d-6         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-7         [-1, 64, 112, 112]             128\n",
            "       BatchNorm2d-8         [-1, 64, 112, 112]             128\n",
            "              ReLU-9         [-1, 64, 112, 112]               0\n",
            "             ReLU-10         [-1, 64, 112, 112]               0\n",
            "        MaxPool2d-11           [-1, 64, 56, 56]               0\n",
            "        MaxPool2d-12           [-1, 64, 56, 56]               0\n",
            "           Conv2d-13           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-14           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "             ReLU-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "      BatchNorm2d-22           [-1, 64, 56, 56]             128\n",
            "             ReLU-23           [-1, 64, 56, 56]               0\n",
            "             ReLU-24           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-25           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-26           [-1, 64, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-28           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-29           [-1, 64, 56, 56]             128\n",
            "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
            "             ReLU-31           [-1, 64, 56, 56]               0\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-34           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-35           [-1, 64, 56, 56]             128\n",
            "      BatchNorm2d-36           [-1, 64, 56, 56]             128\n",
            "             ReLU-37           [-1, 64, 56, 56]               0\n",
            "             ReLU-38           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-39           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-40           [-1, 64, 56, 56]               0\n",
            "           Conv2d-41          [-1, 128, 28, 28]          73,728\n",
            "           Conv2d-42          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
            "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
            "             ReLU-45          [-1, 128, 28, 28]               0\n",
            "             ReLU-46          [-1, 128, 28, 28]               0\n",
            "           Conv2d-47          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-48          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-49          [-1, 128, 28, 28]             256\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "           Conv2d-51          [-1, 128, 28, 28]           8,192\n",
            "           Conv2d-52          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
            "             ReLU-55          [-1, 128, 28, 28]               0\n",
            "             ReLU-56          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-57          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-58          [-1, 128, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-60          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-61          [-1, 128, 28, 28]             256\n",
            "      BatchNorm2d-62          [-1, 128, 28, 28]             256\n",
            "             ReLU-63          [-1, 128, 28, 28]               0\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-66          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-67          [-1, 128, 28, 28]             256\n",
            "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
            "             ReLU-69          [-1, 128, 28, 28]               0\n",
            "             ReLU-70          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-71          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-72          [-1, 128, 28, 28]               0\n",
            "           Conv2d-73          [-1, 256, 14, 14]         294,912\n",
            "           Conv2d-74          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-75          [-1, 256, 14, 14]             512\n",
            "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
            "             ReLU-77          [-1, 256, 14, 14]               0\n",
            "             ReLU-78          [-1, 256, 14, 14]               0\n",
            "           Conv2d-79          [-1, 256, 14, 14]         589,824\n",
            "           Conv2d-80          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-81          [-1, 256, 14, 14]             512\n",
            "      BatchNorm2d-82          [-1, 256, 14, 14]             512\n",
            "           Conv2d-83          [-1, 256, 14, 14]          32,768\n",
            "           Conv2d-84          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-85          [-1, 256, 14, 14]             512\n",
            "      BatchNorm2d-86          [-1, 256, 14, 14]             512\n",
            "             ReLU-87          [-1, 256, 14, 14]               0\n",
            "             ReLU-88          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-89          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-90          [-1, 256, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         589,824\n",
            "           Conv2d-92          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-93          [-1, 256, 14, 14]             512\n",
            "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
            "             ReLU-95          [-1, 256, 14, 14]               0\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97          [-1, 256, 14, 14]         589,824\n",
            "           Conv2d-98          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-99          [-1, 256, 14, 14]             512\n",
            "     BatchNorm2d-100          [-1, 256, 14, 14]             512\n",
            "            ReLU-101          [-1, 256, 14, 14]               0\n",
            "            ReLU-102          [-1, 256, 14, 14]               0\n",
            "      BasicBlock-103          [-1, 256, 14, 14]               0\n",
            "      BasicBlock-104          [-1, 256, 14, 14]               0\n",
            "          Conv2d-105            [-1, 512, 7, 7]       1,179,648\n",
            "          Conv2d-106            [-1, 512, 7, 7]       1,179,648\n",
            "     BatchNorm2d-107            [-1, 512, 7, 7]           1,024\n",
            "     BatchNorm2d-108            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-109            [-1, 512, 7, 7]               0\n",
            "            ReLU-110            [-1, 512, 7, 7]               0\n",
            "          Conv2d-111            [-1, 512, 7, 7]       2,359,296\n",
            "          Conv2d-112            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
            "     BatchNorm2d-114            [-1, 512, 7, 7]           1,024\n",
            "          Conv2d-115            [-1, 512, 7, 7]         131,072\n",
            "          Conv2d-116            [-1, 512, 7, 7]         131,072\n",
            "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
            "     BatchNorm2d-118            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-119            [-1, 512, 7, 7]               0\n",
            "            ReLU-120            [-1, 512, 7, 7]               0\n",
            "      BasicBlock-121            [-1, 512, 7, 7]               0\n",
            "      BasicBlock-122            [-1, 512, 7, 7]               0\n",
            "          Conv2d-123            [-1, 512, 7, 7]       2,359,296\n",
            "          Conv2d-124            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-125            [-1, 512, 7, 7]           1,024\n",
            "     BatchNorm2d-126            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-127            [-1, 512, 7, 7]               0\n",
            "            ReLU-128            [-1, 512, 7, 7]               0\n",
            "          Conv2d-129            [-1, 512, 7, 7]       2,359,296\n",
            "          Conv2d-130            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-131            [-1, 512, 7, 7]           1,024\n",
            "     BatchNorm2d-132            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-133            [-1, 512, 7, 7]               0\n",
            "            ReLU-134            [-1, 512, 7, 7]               0\n",
            "      BasicBlock-135            [-1, 512, 7, 7]               0\n",
            "      BasicBlock-136            [-1, 512, 7, 7]               0\n",
            "          Conv2d-137            [-1, 512, 7, 7]         262,656\n",
            "            ReLU-138            [-1, 512, 7, 7]               0\n",
            "        Upsample-139          [-1, 512, 14, 14]               0\n",
            "          Conv2d-140          [-1, 256, 14, 14]          65,792\n",
            "            ReLU-141          [-1, 256, 14, 14]               0\n",
            "          Conv2d-142          [-1, 512, 14, 14]       3,539,456\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "        Upsample-144          [-1, 512, 28, 28]               0\n",
            "          Conv2d-145          [-1, 128, 28, 28]          16,512\n",
            "            ReLU-146          [-1, 128, 28, 28]               0\n",
            "          Conv2d-147          [-1, 256, 28, 28]       1,474,816\n",
            "            ReLU-148          [-1, 256, 28, 28]               0\n",
            "        Upsample-149          [-1, 256, 56, 56]               0\n",
            "          Conv2d-150           [-1, 64, 56, 56]           4,160\n",
            "            ReLU-151           [-1, 64, 56, 56]               0\n",
            "          Conv2d-152          [-1, 256, 56, 56]         737,536\n",
            "            ReLU-153          [-1, 256, 56, 56]               0\n",
            "        Upsample-154        [-1, 256, 112, 112]               0\n",
            "          Conv2d-155         [-1, 64, 112, 112]           4,160\n",
            "            ReLU-156         [-1, 64, 112, 112]               0\n",
            "          Conv2d-157        [-1, 128, 112, 112]         368,768\n",
            "            ReLU-158        [-1, 128, 112, 112]               0\n",
            "        Upsample-159        [-1, 128, 224, 224]               0\n",
            "          Conv2d-160         [-1, 64, 224, 224]         110,656\n",
            "            ReLU-161         [-1, 64, 224, 224]               0\n",
            "          Conv2d-162          [-1, 6, 224, 224]             390\n",
            "================================================================\n",
            "Total params: 28,976,646\n",
            "Trainable params: 28,976,646\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 417.65\n",
            "Params size (MB): 110.54\n",
            "Estimated Total Size (MB): 528.76\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7rAEQCUEI2v",
        "colab_type": "text"
      },
      "source": [
        "# Define the main training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjt9JeTuDY6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import torch.nn.functional as F\n",
        "from loss import dice_loss\n",
        "\n",
        "checkpoint_path = \"checkpoint.pth\"\n",
        "\n",
        "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
        "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
        "\n",
        "    pred = torch.sigmoid(pred)\n",
        "    dice = dice_loss(pred, target)\n",
        "\n",
        "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
        "\n",
        "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
        "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
        "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def print_metrics(metrics, epoch_samples, phase):\n",
        "    outputs = []\n",
        "    for k in metrics.keys():\n",
        "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
        "\n",
        "    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
        "\n",
        "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
        "    best_loss = 1e10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        since = time.time()\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            metrics = defaultdict(float)\n",
        "            epoch_samples = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = calc_loss(outputs, labels, metrics)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                epoch_samples += inputs.size(0)\n",
        "\n",
        "            print_metrics(metrics, epoch_samples, phase)\n",
        "            epoch_loss = metrics['loss'] / epoch_samples\n",
        "\n",
        "            if phase == 'train':\n",
        "              scheduler.step()\n",
        "              for param_group in optimizer.param_groups:\n",
        "                  print(\"LR\", param_group['lr'])\n",
        "\n",
        "            # save the model weights\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                print(f\"saving best model to {checkpoint_path}\")\n",
        "                best_loss = epoch_loss\n",
        "                torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(torch.load(checkpoint_path))\n",
        "    return model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adcdAu9ZEOLG",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfxgL303EMiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "da0bacc5-3b0e-40a1-8969-f2c4d320bf1e"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "\n",
        "num_class = 6\n",
        "model = ResNetUNet(num_class).to(device)\n",
        "\n",
        "# freeze backbone layers\n",
        "for l in model.base_layers:\n",
        "  for param in l.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
        "\n",
        "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train: bce: 0.096487, dice: 0.943085, loss: 0.519786\n",
            "LR 0.0001\n",
            "val: bce: 0.019246, dice: 0.747698, loss: 0.383472\n",
            "saving best model to checkpoint.pth\n",
            "0m 21s\n",
            "Epoch 1/29\n",
            "----------\n",
            "train: bce: 0.012979, dice: 0.486005, loss: 0.249492\n",
            "LR 0.0001\n",
            "val: bce: 0.012914, dice: 0.256444, loss: 0.134679\n",
            "saving best model to checkpoint.pth\n",
            "0m 21s\n",
            "Epoch 2/29\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcRgjfk5D-kP",
        "colab_type": "text"
      },
      "source": [
        "## Use the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXRtpxHRET-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "model.eval()   # Set model to the evaluation mode\n",
        "\n",
        "# Create a new simulation dataset for testing\n",
        "test_dataset = SimDataset(3, transform = trans)\n",
        "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
        "\n",
        "# Get the first batch\n",
        "inputs, labels = next(iter(test_loader))\n",
        "inputs = inputs.to(device)\n",
        "labels = labels.to(device)\n",
        "print('inputs.shape', inputs.shape)\n",
        "print('labels.shape', labels.shape)\n",
        "\n",
        "# Predict\n",
        "pred = model(inputs)\n",
        "# The loss functions include the sigmoid function.\n",
        "pred = torch.sigmoid(pred)\n",
        "pred = pred.data.cpu().numpy()\n",
        "print('pred.shape', pred.shape)\n",
        "\n",
        "# Change channel-order and make 3 channels for matplot\n",
        "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
        "\n",
        "# Map each channel (i.e. class) to each color\n",
        "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
        "pred_rgb = [helper.masks_to_colorimg(x) for x in pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPQyJc4YD39T",
        "colab_type": "text"
      },
      "source": [
        "## Left: Input image, Middle: Correct mask (Ground-truth), Rigth: Predicted mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6dkJZLBCv4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsfxcw0-DZdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}